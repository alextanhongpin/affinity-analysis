{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori Algorithm\n",
    "\n",
    "- a classic algorithm used in data mining for learning association rules\n",
    "- it can be used to find items that are purchased together more frequently than others\n",
    "\n",
    "## Useful tips\n",
    "\n",
    "### Mapping through rows and columns in an array\n",
    "\n",
    "Create an `np.vectorize` to perform mapping. Let's say we are given an array of items, and for each rows and columns, we want to just take the initials:\n",
    "\n",
    "```python\n",
    "items = np.array([['Mango', 'Onion', 'Nintendo', 'Key-chain', 'Eggs', 'Yo-yo'],\n",
    "                  ['Doll', 'Onion', 'Nintendo', 'Key-chain', 'Eggs', 'Yo-yo'],\n",
    "                  ['Mango', 'Apple', 'Key-chain', 'Eggs'],\n",
    "                  ['Mango', 'Umbrella', 'Corn', 'Key-chain', 'Yo-yo'],\n",
    "                  ['Corn', 'Onion', 'Onion', 'Key-chain', 'Ice-cream', 'Eggs']])\n",
    "\n",
    "# Create a new np function that takes the first character from each\n",
    "# items in the array (for simplification)\n",
    "take_first = lambda x: x[0]\n",
    "f = np.vectorize(take_first)\n",
    "\n",
    "# Apply the function to the items\n",
    "# Note that we also use frozenset to remove duplicates from each transaction\n",
    "data = [frozenset(f(i)) for i in items]\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```python\n",
    "[frozenset({'E', 'K', 'M', 'N', 'O', 'Y'}),\n",
    " frozenset({'D', 'E', 'K', 'N', 'O', 'Y'}),\n",
    " frozenset({'A', 'E', 'K', 'M'}),\n",
    " frozenset({'C', 'K', 'M', 'U', 'Y'}),\n",
    " frozenset({'C', 'E', 'I', 'K', 'O'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import reduce\n",
    "from itertools import combinations\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Every row is a transaction, and every column represent the item bought\n",
    "# Note that in a single transaction, there can be similar items bought\n",
    "items = np.array([['Mango', 'Onion', 'Nintendo', 'Key-chain', 'Eggs', 'Yo-yo'],\n",
    "                  ['Doll', 'Onion', 'Nintendo', 'Key-chain', 'Eggs', 'Yo-yo'],\n",
    "                  ['Mango', 'Apple', 'Key-chain', 'Eggs'],\n",
    "                  ['Mango', 'Umbrella', 'Corn', 'Key-chain', 'Yo-yo'],\n",
    "                  ['Corn', 'Onion', 'Onion', 'Key-chain', 'Ice-cream', 'Eggs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each index `i` will represent a class:\n",
      "\n",
      "0 => Apple\n",
      "1 => Corn\n",
      "2 => Doll\n",
      "3 => Eggs\n",
      "4 => Ice-cream\n",
      "5 => Key-chain\n",
      "6 => Mango\n",
      "7 => Nintendo\n",
      "8 => Onion\n",
      "9 => Umbrella\n",
      "10 => Yo-yo\n"
     ]
    }
   ],
   "source": [
    "# Create a new label encoder to learn the mappings\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the mappings to learn them\n",
    "le.fit(np.hstack(items))\n",
    "# le.fit(list(set(np.hstack(items)))) # Will this be more performant?\n",
    "\n",
    "print('Each index `i` will represent a class:\\n')\n",
    "for i, v in enumerate(le.classes_):\n",
    "    print('{} => {}'.format(i, v))\n",
    "\n",
    "# le.transform(['A', 'M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({3, 5, 6, 7, 8, 10}),\n",
       " frozenset({2, 3, 5, 7, 8, 10}),\n",
       " frozenset({0, 3, 5, 6}),\n",
       " frozenset({1, 5, 6, 9, 10}),\n",
       " frozenset({1, 3, 4, 5, 8})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have learned the mappings, let's apply it to our dataset\n",
    "# We will also remove duplicate items from the array using frozenset\n",
    "# There is an added advantage of being able to check intersection too between sets using frozenset\n",
    "encoded_items = [frozenset(le.transform(i)) for i in items]\n",
    "encoded_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our minimum support of 2, which means that there has to be at least 2 transactions\n",
    "# for the item to be support\n",
    "MIN_SUPPORT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 10,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 10]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the individual items so that we can count them\n",
    "singles = map(lambda x: list(x), encoded_items)\n",
    "singles = reduce(lambda x, y: y + x, singles)\n",
    "singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1, 1: 2, 2: 1, 3: 4, 4: 1, 5: 5, 6: 3, 7: 2, 8: 3, 9: 1, 10: 3})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the count of occurances for each item in the transactions\n",
    "singles_cnt = Counter(singles)\n",
    "singles_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 4, 5: 5, 6: 3, 8: 3, 10: 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once we have the counter, we filter those that has a minimum support of 2 only\n",
    "# or items that appears twice only\n",
    "singles_cnt = {k: v for k, v in list(singles_cnt.items()) \n",
    "               if v > MIN_SUPPORT}\n",
    "singles_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 5),\n",
       " (3, 8),\n",
       " (3, 6),\n",
       " (3, 10),\n",
       " (5, 8),\n",
       " (5, 6),\n",
       " (5, 10),\n",
       " (8, 6),\n",
       " (8, 10),\n",
       " (6, 10)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once we have filtered items that has a minimum support of two, we will now \n",
    "# check for the support for pairs of items\n",
    "data_singles = list(singles_cnt.keys())\n",
    "\n",
    "# We use itertools.combinations to ensure only unique combinations are created\n",
    "# r indicate the length of items in each combination\n",
    "pairs = list(combinations(data_singles, r=2))\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(3, 5): 4,\n",
       "         (3, 6): 2,\n",
       "         (3, 8): 3,\n",
       "         (3, 10): 2,\n",
       "         (5, 6): 3,\n",
       "         (5, 8): 3,\n",
       "         (5, 10): 3,\n",
       "         (6, 10): 2,\n",
       "         (8, 6): 1,\n",
       "         (8, 10): 2})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_fs = []\n",
    "for i in pairs:\n",
    "    for j in encoded_items:\n",
    "        if frozenset(list(i)).issubset(j):\n",
    "            pairs_fs.append(i)\n",
    "            continue\n",
    "\n",
    "pairs_fs = Counter(pairs_fs)\n",
    "pairs_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3, 5): 4, (3, 8): 3, (5, 6): 3, (5, 8): 3, (5, 10): 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, we filter only pairs that has a minimum support of 2\n",
    "pairs_fs = {k: v for k, v in list(pairs_fs.items()) if v > MIN_SUPPORT}\n",
    "pairs_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 6, 8, 10]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we get triples with minimum support of 2\n",
    "data_pairs = [list(i) for i in pairs_fs.keys()]\n",
    "\n",
    "# Flatten it to get all the possible values\n",
    "data_pairs = list(set(reduce(lambda x, y: x + y, data_pairs)))\n",
    "\n",
    "data_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you buy Eggs, Key-chain, you might like Apple, Mango too.\n",
      "If you buy Key-chain, Mango, you might like Apple, Eggs too.\n"
     ]
    }
   ],
   "source": [
    "data_pairs_recommend = [list(i) for i in pairs_fs.keys()]\n",
    "# Provide recomendations for data_pairs\n",
    "for i in data_pairs_recommend:\n",
    "    for j in encoded_items:\n",
    "        if frozenset(i).issubset(j):\n",
    "            items_to_recommend = list(j.difference(i))\n",
    "            if len(items_to_recommend) < 3:\n",
    "                items_to_recommend_classes = ', '.join(le.inverse_transform(items_to_recommend))\n",
    "                items_current_classes = ', '.join(le.inverse_transform(i))\n",
    "                print('If you buy {}, you might like {} too.'.format(items_current_classes, items_to_recommend_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 5, 6),\n",
       " (3, 5, 8),\n",
       " (3, 5, 10),\n",
       " (3, 6, 8),\n",
       " (3, 6, 10),\n",
       " (3, 8, 10),\n",
       " (5, 6, 8),\n",
       " (5, 6, 10),\n",
       " (5, 8, 10),\n",
       " (6, 8, 10)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples = list(combinations(data_pairs, r=3))\n",
    "triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(3, 5, 6): 2,\n",
       "         (3, 5, 8): 3,\n",
       "         (3, 5, 10): 2,\n",
       "         (3, 6, 8): 1,\n",
       "         (3, 6, 10): 1,\n",
       "         (3, 8, 10): 2,\n",
       "         (5, 6, 8): 1,\n",
       "         (5, 6, 10): 2,\n",
       "         (5, 8, 10): 2,\n",
       "         (6, 8, 10): 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples_fs = []\n",
    "for i in triples:\n",
    "    for j in encoded_items:\n",
    "        if frozenset(list(i)).issubset(j):\n",
    "            triples_fs.append(i)\n",
    "            continue\n",
    "\n",
    "triples_fs = Counter(triples_fs)\n",
    "triples_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3, 5, 8): 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, we filter only pairs that has a minimum support of 2\n",
    "triples_fs = {k: v for k, v in list(triples_fs.items()) if v > MIN_SUPPORT}\n",
    "triples_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you buy Eggs, Key-chain, Onion, you might like Mango, Nintendo, Yo-yo too.\n",
      "If you buy Eggs, Key-chain, Onion, you might like Doll, Nintendo, Yo-yo too.\n",
      "If you buy Eggs, Key-chain, Onion, you might like Corn, Ice-cream too.\n"
     ]
    }
   ],
   "source": [
    "# Check recommendation for users that purchased 3, 5 and 8 too\n",
    "data_triples = [list(i) for i in triples_fs.keys()]\n",
    "data_triples\n",
    "\n",
    "for i in data_triples:\n",
    "    for j in encoded_items:\n",
    "        if frozenset(i).issubset(j):\n",
    "            items_to_recommend = list(j.difference(i))\n",
    "            items_to_recommend_classes = ', '.join(le.inverse_transform(items_to_recommend))\n",
    "            items_current_classes = ', '.join(le.inverse_transform(i))\n",
    "            print('If you buy {}, you might like {} too.'.format(items_current_classes, items_to_recommend_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
